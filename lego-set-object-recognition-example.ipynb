{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"source":["**Overview**\n","\n","In this example, we are going to use Open CV to detect the Lego piece.  The background of this data set is white, so the best place to test the approach is with a white piece.\n","\n","**Setup**\n","\n","We start by importing the libraries we need.  OpenCV imshow doesn't work in this notebook, so we'll need to use matplotlib."]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"0c20beb1f1169186b46fef6360805c4e669d1e65","trusted":true},"outputs":[],"source":["import cv2\n","import numpy as np\n","import os\n","from matplotlib import pyplot as plt\n","\n","#see files in kaggle directory\n","#listfiles=os.listdir(\"../input\")\n","#print(listfiles)"]},{"cell_type":"markdown","metadata":{"_uuid":"7dbbd2460f52b50d44acbd5bc55d0350582f8115"},"source":["I want to show you what each image looks like after each step, so I am creating a function that will make it easy to preview each image as we go.\n","\n","OpenCV uses BGR while matplotlib uses RGB, so we need to make sure that put these conversion in so the picture look accurate (you can try previewing without these if you like to test)."]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"56c345680f1de265b462c265c39b5533e4880780","trusted":true},"outputs":[],"source":["# We will be previewing images alongthe way, so lets create a function\n","def previewImg(text,img_preview,grayscale=False):\n","    #plt.imshow(img_preview)\n","    if grayscale==False:\n","        #convert a color image from BGR to RGB before previewing\n","        plt.imshow(cv2.cvtColor(img_preview, cv2.COLOR_BGR2RGB))\n","    else:\n","        #option for Grayscale images\n","        plt.imshow(cv2.cvtColor(img_preview, cv2.COLOR_GRAY2RGB))\n","    plt.title(text)\n","    plt.show()\n"]},{"cell_type":"markdown","metadata":{"_uuid":"053962aaa82b0820b563029b45d109523a766ad4"},"source":["Let's load the starting point.  The example image and it's background."]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"ab0b91abbf7fbc542045548b9c1ceac21a8e86c5","trusted":true},"outputs":[],"source":["#load the example.  It is a white piece, the most difficult to detect!\n","img_example=cv2.imread('../input/example_2_Base Image.jpg')\n","\n","#load a background, so we can extract it and make it easy to detect the object.\n","img_bg=cv2.imread('../input/background_backlit_A.jpg')"]},{"cell_type":"markdown","metadata":{"_uuid":"33f64bd0b3db9647ac061bf0362ce19d8de33325"},"source":["**Staring Point**\n","\n","Visually this is our starting point (I'm using our defined function above)."]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"2cb78953637c0d643b0b2c9fa35509e02b0642d0","trusted":true},"outputs":[],"source":["# our starting Point\n","previewImg('Background Image',img_bg)\n","previewImg('Example Image',img_example)"]},{"cell_type":"markdown","metadata":{"_uuid":"4d5f04cd93d098b2b3ab4f2266c2ef73003a736f"},"source":["**Step 1**\n","\n","We know proceed to convert these images to Grayscale, and then preview them."]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"b46959bc53fa3c585b3c8f62c7df1dd588cdbdd9","trusted":true},"outputs":[],"source":["# Background - Gray\n","img_bg_gray=cv2.cvtColor(img_bg, cv2.COLOR_BGR2GRAY)\n","previewImg(\"Background Gray\",img_bg_gray,True)\n","# Image - Gray\n","img_gray=cv2.cvtColor(img_example, cv2.COLOR_BGR2GRAY)\n","previewImg(\"Image Gray\",img_gray,True)"]},{"cell_type":"markdown","metadata":{"_uuid":"2cd722c1d879f545adabb0993c7f2ce6b60201d4"},"source":["**Step 2**\n","\n","The background is the same in each images, so we will subtract the background from the base image to make sure the object is much more detectable.\n","\n","The output is the \"difference\" between both images (you can play around and skipt his step)."]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"28f448a5439abe5c9cb2e057d41ab4300c95e3f0","trusted":true},"outputs":[],"source":["# Calculate Difference\n","diff_gray=cv2.absdiff(img_bg_gray,img_gray)\n","previewImg(\"Pre-Diff\",diff_gray,True)"]},{"cell_type":"markdown","metadata":{"_uuid":"f7fc583b50956520ecaef4ec721e27c627496214"},"source":["**Step 3**\n","\n","Apply some Gaussian blur, which makes the image smoother between pixels (and helps us focus the detection on sharper contours)."]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"60a19a3a5aa508bbee0df22335ce07a8b9afdaa7","trusted":true},"outputs":[],"source":["# Diff Blur\n","diff_gray_blur = cv2.GaussianBlur(diff_gray,(5,5),0)\n","previewImg(\"Pre-Diff Blur\",diff_gray_blur,True)"]},{"cell_type":"markdown","metadata":{"_uuid":"9fb7cb533fa5b021b91bf16095072aef0851446f"},"source":["**Step 4**\n","\n","Now we apply Thresholding, which means that the algorithm will decide to placer pixels in either the background or foreground (binary).\n","\n","We use the Otsu algorithm which iterates across the ideal values for this separation."]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"fec24db9c5e9c87df3767ae663de40580494b668","trusted":true},"outputs":[],"source":["# find otsu's threshold value with OpenCV function\n","ret, img_tresh = cv2.threshold(diff_gray_blur,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n","previewImg(\"Otsu Treshold\",img_tresh,True)"]},{"cell_type":"markdown","metadata":{"_uuid":"ed795999afc5d327b0d7df218487b83ca0d03f19"},"source":["**Step 5**\n","\n","We use the image from Step 4 to detect the contour using OpenCV findContours function and draw them in green color.\n","\n","We now have the contours, so we will draw them on top of the Original image."]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"620e41873eafab9ff3679f25e022e67f71e8c22c","trusted":true},"outputs":[],"source":["# let's now draw the contour\n","a1, arr_cnt, a2 = cv2.findContours(img_tresh, cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n","\n","# let's copy the example image, so we don't paint over it\n","img_with_allcontours=img_example.copy()\n","\n","cv2.drawContours(img_with_allcontours, arr_cnt, -1, (0,255,0), 3)\n","previewImg('Contours',img_with_allcontours)\n","\n","# !!! It may be possible that various contours are showing at this stage, we'll solve that below."]},{"cell_type":"markdown","metadata":{"_uuid":"fedee3da3ac19087a7b7ffedd170704ce94d18b0"},"source":["**Optional Step**\n","\n","It may be possible that we have more than one object/Lego piece in the picture or the algorithm is detecting some noise as contours.\n","\n","This step here let's us eliminate these \"noises\".   The data set I'm running this Kernel on is cleaned, this would only apply to real case scenarios.\n","\n","I run 3 conditions:\n","* minimum area to consider an object (e.g. anything smaller than a 1x1 brick I will consider noise).\n","* if the object is sitting in an edge (the brick is clipped)\n","* if the object has a ratio that exceeds the objects (in this case, the 1x6 plate is the thinnest piece to detect, anything with a longer ratio will be considered noise)"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"c23c5ec393b946de49ebcc3ba9aa4310b564bb34","trusted":true},"outputs":[],"source":["# Just in case, we need to make sure we 'weed out' any contour noise that might generate as images have variations.\n","\n","# get the dimensions of the image\n","height, width, channels = img_example.shape\n","\n","# shorten the variable names\n","w=width\n","h=height\n","\n","validcontours=[]\n","contour_index=-1\n","\n","# iterate through each contour found\n","for i in arr_cnt:\n","\n","    contour_index=contour_index+1\n","    ca=cv2.contourArea(i)\n","\n","    # Calculate W/H Ratio of image\n","    x,y,w,h = cv2.boundingRect(i)\n","    aspect_ratio = float(w)/h\n","\n","    # Flag as edge_noise if the object is at a Corner\n","    # Contours at the edges of the image are most likely not valid contours\n","    edge_noise=False\n","    # if contour starts at x=0 then it's on th edge\n","    if x==0:\n","        edge_noise=True\n","    if y==0:\n","        edge_noise=True\n","    # if the contour x value + its contour width exceeds image width, it is on an edge\n","    if (x+w)==width:\n","        edge_noise=True\n","    if (y+h)==height:\n","        edge_noise=True\n","            \n","    # DISCARD noise with measure by area (1x1 round plate dimensions is 1300)\n","    # if by any chance a contour is drawn on one pixel, this catches it.\n","    if ca>1300:\n","\n","        # DISCARD as noise if W/H ratio > 7 to 1 (1x6 plate is 700px to 100px)\n","        # the conveyor belt has a join line that sometimes is detected as a contour, this ignores it based on w/h ratio\n","        if aspect_ratio<=6:\n","            \n","            # DISCARD if at the Edge\n","            if edge_noise==False:\n","                validcontours.append(contour_index)\n","\n","# copy the original picture\n","img_withcontours=img_example.copy()\n","                \n","# call out if more than 1 valid contour is found\n","if len(validcontours)>1:\n","    print(\"There is more than 1 object in the picture\")\n","else:\n","    if len(validcontours)==1:\n","        print(\"One object detected\")\n","    else:\n","        print(\"No objects detected\")\n","        # FYI: code below will most likely error out as it tries to iterate on an array\n","    \n","# it might be possible we have more than 1 validcontour, iterating through them here\n","# if there is zero contours, this most likely will error out\n","for i in validcontours:                           \n","    cv2.drawContours(img_withcontours, arr_cnt,validcontours[i], (0,255,0), 3)\n","    previewImg('Contours',img_withcontours)\n","\n"]},{"cell_type":"markdown","metadata":{"_uuid":"681edec0f93eae7a382153bcf4c80df7ca544ac4"},"source":["**Optional Step**\n","\n","If you need to crop the image, it will be useful to be able to identify a rectangle.\n","\n","To achieve this, use OpenCV bounding rectangle function."]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"567106777e3a747df06f55f246250ac54ff505fa","trusted":true},"outputs":[],"source":["# Display a Bounding Rectangle\n","img_withrectangle=img_example.copy()\n","for i in validcontours:\n","    x,y,w,h = cv2.boundingRect(arr_cnt[i])\n","    cv2.rectangle(img_withrectangle,(x,y),(x+w,y+h),(0,255,0),2)\n","    previewImg('Bounding Rectangle',img_withrectangle)"]}],"metadata":{"kernelspec":{"display_name":"Python 3.10.8 64-bit (microsoft store)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.8"},"vscode":{"interpreter":{"hash":"3c364255924380f9b9fb9efb05af0655c716a55cbcea132fc4277816a1f11106"}}},"nbformat":4,"nbformat_minor":1}
